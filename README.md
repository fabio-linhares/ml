<p align="center">
  <img src="https://ufal.br/ufal/comunicacao/identidade-visual/brasao/ods/ufal_ods1.png" alt="Logo UFAL" width="320"/>
</p>



<h1 align="center">
  Lista de Exerc√≠cios ‚Äî Aprendizagem de M√°quina<br>
  Mestrado em Inform√°tica ‚Äî UFAL
</h1>

<p align="center">
  <b>Disciplina:</b> Aprendizagem de M√°quina<br>
  <b>Professor:</b> Evandro de Barros Costa (<a href="mailto:evandro@ic.ufal.br">evandro@ic.ufal.br</a>)<br>
  <b>Departamento:</b> Instituto de Computa√ß√£o ‚Äî UFAL<br>
  <b>Lattes:</b> <a href="http://lattes.cnpq.br/5760364940162939">http://lattes.cnpq.br/5760364940162939</a>
</p>

<p align="center">
  <b>Autor:</b> F√°bio Linhares<br>
  <b>Lattes:</b> <a href="http://lattes.cnpq.br/7908261028551208">http://lattes.cnpq.br/7908261028551208</a>
</p>

<p align="center">
  <a href="https://tutu.zerocopia.com.br/" target="_blank">
    <img src="https://img.shields.io/badge/Acessar%20Aplica√ß√£o-Streamlit-FF4B4B?style=for-the-badge&logo=streamlit" alt="Streamlit App">
  </a>
</p>

<p align="center">
  <i>Este trabalho integra as atividades da disciplina de Aprendizagem de M√°quina do Programa de P√≥s-Gradua√ß√£o em Inform√°tica (Mestrado), Universidade Federal de Alagoas.</i>
</p>

<div style="text-align: justify;">

# Lista de Exerc√≠cios 1

**Resumo:** Resolu√ß√£o completa, quest√£o a quest√£o, com c√≥digo, resultados e material de suporte (prints dos c√°lculos manuais). Este README descreve a estrutura do reposit√≥rio, como reproduzir os experimentos, as decis√µes metodol√≥gicas, resultados-chave e observa√ß√µes cr√≠ticas.

</div>

---

## √çndice

1. [Estrutura do reposit√≥rio](#estrutura-do-reposit√≥rio)
2. [Como replicar (quickstart)](#como-replicar-quickstart)
3. [Dados (`clientes.csv`)](#dados-clientescsv)
4. [Quest√£o 1 ‚Äî Expans√£o da base e constru√ß√£o manual de √°rvores](#quest√£o-1---expans√£o-da-base-e-constru√ß√£o-manual-de-√°rvores)
5. [Quest√£o 2 ‚Äî Implementa√ß√£o com bibliotecas (Scikit-learn) e c√≥digo pr√≥prio](#quest√£o-2---implementa√ß√£o-com-bibliotecas-scikit-learn-e-c√≥digo-pr√≥prio)
6. [Quest√£o 3 ‚Äî Dataset do Kaggle (Heart Disease) e regras diretas (RIPPER)](#quest√£o-3---dataset-do-kaggle-heart-disease-e-regras-diretas-ripper)
7. [Quest√µes 4 & 5 ‚Äî Overfitting, Underfitting e o papel do C4.5](#quest√µes-4--5---overfitting-underfitting-e-o-papel-do-c45)
8. [Quest√£o 6 ‚Äî k-Nearest Neighbors (kNN): explica√ß√£o, exemplo num√©rico e limita√ß√µes](#quest√£o-6---k%E2%80%8Bnearest-neighbors-knn-explica√ß√£o-exemplo-num√©rico-e-limita√ß√µes)
9. [Reprodutibilidade, limita√ß√µes e notas metodol√≥gicas](#reprodutibilidade-limita√ß√µes-e-notas-metodol√≥gicas)
10. [Contribui√ß√µes, contato e licen√ßa](#contribui√ß√µes-contato-e-licen√ßa)

---

## Estrutura do reposit√≥rio

```
.
‚îú‚îÄ‚îÄ app.py                     # Aplica√ß√£o web interativa com Streamlit
‚îú‚îÄ‚îÄ backup/                    # Arquivos de backup de vers√µes anteriores
‚îú‚îÄ‚îÄ class_cart.py              # Classe wrapper para o algoritmo CART
‚îú‚îÄ‚îÄ class_c45.py               # Classe wrapper para o algoritmo C4.5
‚îú‚îÄ‚îÄ class_id3.py               # Classe wrapper para o algoritmo ID3
‚îú‚îÄ‚îÄ clientes.csv               # Base de dados expandida (30 inst√¢ncias) - Quest√£o 1
‚îú‚îÄ‚îÄ download_heart_dataset.py  # Script para baixar o dataset da Quest√£o 3
‚îú‚îÄ‚îÄ evaluate_models.py         # Script para avalia√ß√£o dos modelos (m√©tricas e matrizes)
‚îú‚îÄ‚îÄ heart_disease_ripper.py    # Implementa√ß√£o da an√°lise com RIPPER (Quest√£o 3)
‚îú‚îÄ‚îÄ knn_classifier.py          # Implementa√ß√£o do classificador kNN (Quest√£o 6)
‚îú‚îÄ‚îÄ optimized_tree.py          # N√∫cleo otimizado que implementa a l√≥gica das √°rvores
‚îú‚îÄ‚îÄ README.md                  # Este arquivo de documenta√ß√£o
‚îú‚îÄ‚îÄ requirements.txt           # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ resultados_img/            # Imagens das matrizes de confus√£o e das √°rvores de decis√£o
‚îÇ   ‚îú‚îÄ‚îÄ c45.PNG
‚îÇ   ‚îú‚îÄ‚îÄ cart.PNG
‚îÇ   ‚îú‚îÄ‚îÄ id3.PNG
‚îÇ   ‚îú‚îÄ‚îÄ matriz_confusao_c4.5.png
‚îÇ   ‚îú‚îÄ‚îÄ matriz_confusao_cart.png
‚îÇ   ‚îî‚îÄ‚îÄ matriz_confusao_id3.png
‚îî‚îÄ‚îÄ sodeusnacausa/             # Screenshots com os c√°lculos manuais (Quest√£o 1)
```

---

<div style="text-align: justify;">

## Instala√ß√£o e Execu√ß√£o

Recomendamos a cria√ß√£o de um ambiente virtual para isolar as depend√™ncias do projeto.
Ainda assim, voc√™ tem total liberdade para adotar o procedimento que considerar mais conveniente. Nossa orienta√ß√£o contempla duas op√ß√µes bastante utilizadas no mercado: **venv** ‚Äì ferramenta nativa e padr√£o do Python para cria√ß√£o de ambientes virtuais, simples e leve ou **Miniconda** ‚Äì uma vers√£o reduzida do Anaconda, que inclui o gerenciador de pacotes Conda sem trazer, por padr√£o, o conjunto extenso de bibliotecas pr√©-instaladas.

### 1. Cria√ß√£o do Ambiente Virtual
**Usando venv** : cria um ambiente isolado em uma pasta chamada `venv`:

```bash
python -m venv venv
```

**Usando Miniconda**: cria um ambiente isolado chamado `lista1_ml` com uma vers√£o espec√≠fica do Python:

```bash
conda create --name lista1_ml python=3.12
```

---

### 2. Ativa√ß√£o e Desativa√ß√£o do Ambiente

√â crucial ativar o ambiente antes de instalar pacotes ou executar a aplica√ß√£o.

**Com venv**

Para ativar:

```bash
# No Linux ou macOS
source venv/bin/activate

# No Windows (PowerShell)
.\venv\Scripts\Activate.ps1
```

Para desativar:

```bash
deactivate
```

**Com Miniconda**

Para ativar:

```bash
conda activate lista1_ml
```

Para desativar:

```bash
conda deactivate
```

---

### 3. Instala√ß√£o das Depend√™ncias

Com o ambiente devidamente ativado, instale todos os pacotes necess√°rios:

```bash
pip install -r requirements.txt
```

---

### 4. Executando a Aplica√ß√£o

Para iniciar o servidor do Streamlit e visualizar a aplica√ß√£o, execute:

```bash
streamlit run app.py 
# acesse http://localhost:8501
```
---

## Quest√£o 1 ‚Äî Expans√£o da base e constru√ß√£o manual de √°rvores

### Objetivos

1. Expandir a base original para 30 exemplos.
2. Construir manualmente tr√™s √°rvores: **ID3**, **C4.5** e **CART**, mostrando c√°lculos.
3. Extrair regras `SE ... ENT√ÉO`.
4. Comparar e recomendar a melhor base de regras.

## Base de Dados

**Descri√ß√£o**


A primeira quest√£o da lista de exerc√≠cios solicitava que, a partir de uma base fornecida pelo ‚Äúgerente do banco‚Äù fosse realizada uma amplia√ß√£o para que contivesse 6 atributos e 30 exemplos divididos entre as classes de Risco Baixo, Moderado e Alto. Como a referida base continha apenas 14 inst√¢ncias, fizemos a adi√ß√£o de 16, distribu√≠das entre as classes solicitadas, mantendo a coer√™ncia com os dados originais. A base final, dispon√≠vel no arquivo `clientes.csv`, possui as seguintes caracter√≠sticas:

* 30 inst√¢ncias
* 6 atributos (Renda, Hist√≥ria de Cr√©dito, Garantia, Idade, Tipo de Emprego e Risco)
* Target/Classe: `Risco` com tr√™s n√≠veis: `Baixo`, `Moderado` e `Alto`.

**Distribui√ß√£o de classes**

* Baixo Risco: 12
* Moderado Risco: 8
* Alto Risco: 10
* Total: 30

> Observa√ß√£o: o arquivo `clientes.csv` foi usado em todas as an√°lises deste exerc√≠cio.

---


### Metodologia e f√≥rmulas utilizadas

* **Entropia:** `Entropy(S) = - Œ£ p_i log2(p_i)`
* **Ganho de Informa√ß√£o (ID3/C4.5):** `Gain(S, A) = Entropy(S) - Œ£ (|S_v|/|S|) Entropy(S_v)`
* **√çndice Gini (CART):** `Gini(S) = 1 - Œ£ p_i^2`

### C√°lculo do n√≥ raiz

* `p_Baixo = 12/30`, `p_Moderado = 8/30`, `p_Alto = 10/30`

* **Entropia (raiz, ID3/C4.5):**

  ```
  Entropy(S) = -[ (12/30)log2(12/30) + (8/30)log2(8/30) + (10/30)log2(10/30) ] ‚âà 1.565
  ```
* **Gini (raiz, CART):**

  ```
  Gini(S) = 1 - [ (12/30)^2 + (8/30)^2 + (10/30)^2 ] ‚âà 0.658
  ```

> Os c√°lculos completos (passo a passo) foram feitos em papel e os prints est√£o em `sodeusnacausa/` .

### √Årvores finais

**ID3**

```
      [ Renda ]
     /    |    \
 ($0-$15k) ($15-$35k) (> $35k)
    |         |          \
 [Hist. Cred] [Hist. Cred] [ Baixo ]
  /  |   \       /   |   \
(R) (D)  (B)   (R) (D) (B)
 |   |    |     |   |   |
[A] [A] [Garantia] [A] [M] [M]
    /    \
  (N)    (AD)
   |      |
  [A]    [M]


Legenda: R=Ruim, D=Desconhecida, B=Boa, N=Nenhuma, AD=Adequada, A=Alto, M=Moderado
```

**C4.5** (semelhante ao ID3, mas com cortes cont√≠nuos)

```
         [Renda]
        /   |    \
  $0-15k $15-35k  >$35k
   |       |        \
 [Alto] [Idade <= 32.5] [Baixo]
```

**CART**

```
  [ Renda = '$0-$15k'? ]
  /                   \
    Sim                    Nao
     |                      |
   [ Alto ]        [ Renda = '> $35k'? ]
       /                  \
         Sim                   Nao
      |                     |
        [ Baixo ]      [ Hist. Cred = 'Ruim'? ]
            /                     \
          Sim                      Nao
           |                        |
             [ Alto ]                [ Moderado ]
```

### Regras extra√≠das

> Observa√ß√£o: em aula eu comentei que n√£o recordava a ocorrencia de over e underfitting em √°rvores de decis√£o. Ap√≥s a realiza√ß√£o destes exerc√≠cios percebi que o overfitting esta mais relacionados √†s √°rvores n√£o podadas (como ID3 puro). J√° o underfitting, que √© menos comum, e talvez isso justifique minha falta de mem√≥ria, pode ocorrer se a √°rvore for excessivamente simplificada ou se os dados forem muito ruidosos.

#### **Regras da √Årvore ID3**
- **R1:** SE Renda = '$0 a $15k' E Hist√≥ria de Cr√©dito = 'Ruim' ENT√ÉO Risco = 'Alto' (Suporte=3, Acur√°cia=100%)
- **R2:** SE Renda = '$0 a $15k' E Hist√≥ria de Cr√©dito = 'Desconhecida' ENT√ÉO Risco = 'Alto' (Suporte=3, Acur√°cia=100%)
- **R3:** SE Renda = '$0 a $15k' E Hist√≥ria de Cr√©dito = 'Boa' E Garantia = 'Nenhuma' ENT√ÉO Risco = 'Alto' (Suporte=1, Acur√°cia=100%)
- **R4:** SE Renda = '$0 a $15k' E Hist√≥ria de Cr√©dito = 'Boa' E Garantia = 'Adequada' ENT√ÉO Risco = 'Moderado' (Suporte=1, Acur√°cia=100%)
- **R5:** SE Renda = '$15 a $35k' E Hist√≥ria de Cr√©dito = 'Ruim' ENT√ÉO Risco = 'Alto' (Suporte=2, Acur√°cia=100%)
- **R6:** SE Renda = '$15 a $35k' E Hist√≥ria de Cr√©dito = 'Desconhecida' ENT√ÉO Risco = 'Moderado' (Suporte=1, Acur√°cia=100%)
- **R7:** SE Renda = '$15 a $35k' E Hist√≥ria de Cr√©dito = 'Boa' ENT√ÉO Risco = 'Moderado' (Suporte=4, Acur√°cia=50%)
- **R8:** SE Renda = 'Acima de $35k' ENT√ÉO Risco = 'Baixo' (Suporte=13, Acur√°cia=76,9%)

#### **Regras da √Årvore C4.5**
- **R1:** SE Renda = '$0 a $15k' ENT√ÉO Risco = 'Alto' (Suporte=8, Acur√°cia=87,5%)
- **R2:** SE Renda = '$15 a $35k' E Idade <= 30.5 E Hist√≥ria de Cr√©dito = 'Desconhecida' ENT√ÉO Risco = 'Moderado' (Suporte=1, Acur√°cia=100%)
- *(Demais ramos seguem l√≥gica semelhante, com regras mais gerais devido √† poda.)*

#### **Regras da √Årvore CART**
- **R1:** SE Renda = '$0 a $15k' ENT√ÉO Risco = 'Alto' (Suporte=8, Acur√°cia=87,5%)
- **R2:** SE Renda != '$0 a $15k' E Renda = 'Acima de $35k' ENT√ÉO Risco = 'Baixo' (Suporte=13, Acur√°cia=76,9%)
- **R3:** SE Renda != '$0 a $15k' E Renda != 'Acima de $35k' E Hist√≥ria de Cr√©dito = 'Ruim' ENT√ÉO Risco = 'Alto' (Suporte=2, Acur√°cia=100%)
- **R4:** SE Renda != '$0 a $15k' E Renda != 'Acima de $35k' E Hist√≥ria de Cr√©dito != 'Ruim' ENT√ÉO Risco = 'Moderado' (Suporte=7, Acur√°cia=71,4%)

---

### (iv) Compara√ß√£o e Sele√ß√£o da Base de Regras

| Crit√©rio           | ID3                                         | C4.5                                  | CART                                 |
|--------------------|---------------------------------------------|---------------------------------------|--------------------------------------|
| **Simplicidade**   | Muitas regras, algumas muito espec√≠ficas    | Menos regras, mais gerais (poda)      | Poucas regras, estrutura bin√°ria     |
| **Exatid√£o (Treino)** | Alta (tende a overfit)                  | Alta, controlada por poda             | Boa, balanceada                      |
| **Interpretabilidade** | Moderada, granularidade pode confundir | Boa                                   | Excelente, l√≥gica bin√°ria clara      |
| **Robustez**       | Baixa (sens√≠vel a ru√≠do)                   | M√©dia (poda ajuda)                    | M√©dia                                |

**Reflex√£o:**

A base de regras do CART √© a mais concisa (4 regras) e possui estrutura bin√°ria de f√°cil interpreta√ß√£o. As regras cobrem todos os casos de forma mutuamente exclusiva. O ID3 gera muitas regras muito espec√≠ficas, sugerindo overfitting. Sinceramene, preferimos o CART pela simplicidade e clareza, **principalmente porque tivemos que fazer a m√£o**, embora tais caracter√≠stias sejam em essencia, fundamentais em sistemas de apoio √† decis√£o. A regra "SE Renda √© alta, ENT√ÉO Risco √© Baixo" √© intuitiva. A leve perda de acur√°cia √© compensada pela interpretabilidade. De modo geral, pareceu-nos que modelos mais simples (C4.5 podado ou CART) tendem a generalizar melhor e, por conta disso, serem prefer√≠veis em dom√≠nios onde interpretabilidade √© cr√≠tica, como na √°rea de finan√ßas, por exemplo.


---

## Quest√£o 2 ‚Äî Implementa√ß√£o com bibliotecas (Scikit-learn) e c√≥digo pr√≥prio

### Arquitetura do C√≥digo

A implementa√ß√£o foi refatorada para uma arquitetura mais robusta e modular:

*   **`optimized_tree.py`**: Atua como o **c√©rebro** do sistema. Cont√©m a classe `OptimizedDecisionTree`, que implementa toda a l√≥gica de constru√ß√£o de √°rvores, incluindo os c√°lculos de m√©tricas (Entropia, Gini, Gain Ratio), divis√µes de dados (categ√≥ricos e cont√≠nuos) e a estrutura da √°rvore. Ele √© projetado para ser configur√°vel e atender aos requisitos espec√≠ficos de cada algoritmo (ID3, C4.5 e CART).
*   **`class_id3.py`, `class_c45.py`, `class_cart.py`**: Funcionam como **wrappers** ou "fachadas". Cada classe simplesmente instancia o motor `OptimizedDecisionTree` com a configura√ß√£o correta (`algorithm='id3'`, `'c45'` ou `'cart'`). Isso elimina a duplica√ß√£o de c√≥digo e centraliza a l√≥gica de decis√£o em um √∫nico local, facilitando a manuten√ß√£o e a compara√ß√£o.

### An√°lise das Diverg√™ncias: Manual vs. C√≥digo

Ao comparar as √°rvores geradas manualmente na quest√£o anterior com as produzidas  nessa implementa√ß√£o √© poss√≠vel notar diverg√™ncias. Essas diferen√ßas n√£o indicam um erro, mas sim destacam a natureza da implementa√ß√£o computacional em contraste com a abordagem manual. As principais raz√µes para isso s√£o:

1.  **Precis√£o e Crit√©rios de Desempate:** Os c√°lculos manuais frequentemente envolvem arredondamentos. O c√≥digo, por outro lado, trabalha com a precis√£o total de ponto flutuante. Uma diferen√ßa m√≠nima no ganho de informa√ß√£o ou no √≠ndice Gini, invis√≠vel manualmente, pode levar o algoritmo a escolher um atributo diferente. Al√©m disso, em caso de empate, o c√≥digo seguir√° uma l√≥gica determin√≠stica (ex: escolher o primeiro atributo da lista), enquanto a escolha manual pode ser arbitr√°ria.

2.  **Tratamento Exaustivo dos Atributos:**
    *   **Atributos Cont√≠nuos (C4.5/CART):** O c√≥digo testa sistematicamente todos os pontos de corte poss√≠veis entre valores √∫nicos e ordenados para encontrar o limiar que maximiza a m√©trica de divis√£o. Manualmente, √© impratic√°vel realizar essa busca exaustiva.
    *   **Atributos Categ√≥ricos (CART):** Para criar uma divis√£o bin√°ria, o algoritmo testa todas as combina√ß√µes de "um valor vs. o resto", garantindo a escolha √≥tima, algo que pode passar despercebido na an√°lise manual.

3.  **Impacto de Hiperpar√¢metros e Generaliza√ß√£o:** A implementa√ß√£o em c√≥digo utiliza hiperpar√¢metros como `max_depth` para controlar a complexidade da √°rvore. Isso √© uma t√©cnica fundamental para evitar o *overfitting* (sobreajuste), resultando em √°rvores potencialmente menores e com maior poder de generaliza√ß√£o. As √°rvores manuais, especialmente a do ID3, foram constru√≠das at√© a pureza total dos ramos, criando regras muito espec√≠ficas que podem n√£o performar bem com dados novos.

Em suma, a √°rvore gerada pelo c√≥digo √© o resultado de um processo mais rigoroso, reproduz√≠vel e alinhado com as boas pr√°ticas de aprendizado de m√°quina, que priorizam a generaliza√ß√£o em detrimento do ajuste perfeito aos dados de treino.

### Resultados de Desempenho (Treinamento)

O sistema de memoiza√ß√£o (`AdvancedMemoizationTable`) implementado em `optimized_tree.py` armazena em cache os resultados de c√°lculos repetitivos (como Entropia e Gini para o mesmo subconjunto de dados). Isso acelera significativamente o treinamento, especialmente em √°rvores mais profundas.

Abaixo est√£o os resultados de uma execu√ß√£o t√≠pica, mostrando o tempo de treinamento e a efici√™ncia do cache:

| Algoritmo | Tempo de Treinamento | Taxa de Acerto do Cache |
| :-------- | :------------------- | :---------------------- |
| **ID3**   | ~0.275s              | ~42.7%                  |
| **C4.5**  | ~0.223s              | ~63.0%                  |
| **CART**  | ~0.299s              | ~67.4%                  |

*Observa√ß√£o: Os tempos podem variar ligeiramente a cada execu√ß√£o. A alta taxa de acerto do cache, especialmente para C4.5 e CART, demonstra a efic√°cia da otimiza√ß√£o, pois muitos n√≥s da √°rvore avaliam os mesmos subconjuntos de dados repetidamente.*

### Observa√ß√µes t√©cnicas

*   `scikit-learn` produz √°rvores bin√°rias por padr√£o (CART) e faz otimiza√ß√µes que reduzem overfitting aparente (ex.: par√¢metros `min_samples_split`, `max_depth`, etc.).
*   Nossa implementa√ß√£o agora reflete essa sofistica√ß√£o, com um motor central que lida com as nuances de cada algoritmo, tornando a compara√ß√£o mais direta e o c√≥digo mais limpo.

### Avalia√ß√£o dos Modelos e An√°lise de Resultados

Para avaliar o desempenho de cada algoritmo, dividimos o dataset em 70% para treino e 30% para teste. O script `evaluate_models.py` foi executado para treinar os modelos e gerar as m√©tricas e visualiza√ß√µes a seguir.

#### M√©tricas de Desempenho Comparativas

A tabela abaixo resume o desempenho de cada modelo no conjunto de teste:

| M√©trica         | ID3     | C4.5    | CART    |
| :-------------- | :------ | :------ | :------ |
| **Acur√°cia**    | 77.78%  | 77.78%  | 77.78%  |
| **Precis√£o**    | 0.80    | 0.61    | 0.80    |
| **Recall**      | 0.78    | 0.78    | 0.78    |
| **F1-Score**    | 0.77    | 0.68    | 0.77    |

*Nota: Precis√£o, Recall e F1-Score s√£o m√©dias ponderadas.*

#### Matrizes de Confus√£o

As matrizes de confus√£o detalham os acertos e erros de cada modelo por classe.

<div style="display: flex; justify-content: center; gap: 32px; align-items: flex-start;">

<div style="text-align: center;">
  <strong>ID3</strong><br>
  <img src="resultados_img/matriz_confusao_id3.png" alt="Matriz de Confus√£o ID3" width="320"/>
</div>

<div style="text-align: center;">
  <strong>C4.5</strong><br>
  <img src="resultados_img/matriz_confusao_c4.5.png" alt="Matriz de Confus√£o C4.5" width="320"/>
</div>

<div style="text-align: center;">
  <strong>CART</strong><br>
  <img src="resultados_img/matriz_confusao_cart.png" alt="Matriz de Confus√£o CART" width="320"/>
</div>

</div>

#### An√°lise das Matrizes

1.  **Acur√°cia Geral:** Todos os tr√™s modelos alcan√ßaram a mesma acur√°cia de **77.78%** no conjunto de teste, acertando 7 das 9 inst√¢ncias. Isso sugere que, para este dataset e com a profundidade de √°rvore limitada (`max_depth=5`), o poder preditivo dos tr√™s algoritmos √© bastante similar.

2.  **Desempenho do ID3 e CART:** Os modelos ID3 e CART apresentaram um comportamento id√™ntico, conforme suas matrizes de confus√£o. Ambos classificaram perfeitamente a classe `Baixo` Risco (4/4 acertos). No entanto, tiveram dificuldade com as outras classes: erraram 1 das 3 inst√¢ncias de `Alto` Risco (classificando-a como `Baixo`) e 1 das 2 de `Moderado` Risco (classificando-a como `Alto`). Isso resultou em uma precis√£o mais baixa para a classe `Moderado` (50%).

3.  **Desempenho do C4.5:** O modelo C4.5 se destacou por classificar perfeitamente tanto a classe `Alto` (3/3) quanto a `Baixo` (4/4). Seu ponto fraco foi a classe `Moderado`, que ele **n√£o conseguiu identificar corretamente nenhuma vez**, classificando as duas inst√¢ncias como `Alto`. Isso explica por que sua precis√£o geral ponderada (0.61) √© significativamente menor que a dos outros modelos, apesar da mesma acur√°cia. O C4.5, neste caso, criou regras que generalizaram demais a classe `Moderado`, absorvendo-a na `Alto`.

**Conclus√£o da An√°lise:** Embora a acur√°cia seja a mesma, os modelos **ID3 e CART** mostram um comportamento mais equilibrado, sendo capazes de identificar, ainda que com alguns erros, todas as tr√™s classes. O **C4.5** demonstrou uma tend√™ncia a "ignorar" a classe minorit√°ria (`Moderado`) em favor das outras, o que pode ser um comportamento indesejado em problemas onde a detec√ß√£o de todas as classes √© cr√≠tica.

#### Visualiza√ß√£o das √Årvores de Decis√£o


<div style="display: flex; justify-content: center; gap: 32px; align-items: flex-start;">

<div style="text-align: center;">
  <strong>ID3</strong><br>
  <img src="resultados_img/id3.PNG" alt="√Årvore de Decis√£o ID3" width="380"/>
</div>

<div style="text-align: center;">
  <strong>C4.5</strong><br>
  <img src="resultados_img/c45.PNG" alt="√Årvore de Decis√£o C4.5" width="380"/>
</div>

<div style="text-align: center;">
  <strong>CART</strong><br>
  <img src="resultados_img/cart.PNG" alt="√Årvore de Decis√£o CART" width="380"/>
</div>

</div>


---

## Quest√£o 3 ‚Äî Dataset do Kaggle (Heart Disease) e regras diretas (RIPPER)

### Dataset escolhido

* **Heart Disease UCI** ‚Äî conjunto cl√°ssico, alvo bin√°rio (`target`), mistura de vari√°veis cont√≠nuas e categ√≥ricas.

### Procedimento e Implementa√ß√£o

Para resolver a depend√™ncia do dataset, foi criado o script `download_heart_dataset.py`. Ao ser executado, ele baixa o conjunto de dados "Heart Disease UCI" do reposit√≥rio OpenML ou, em caso de falha, gera um dataset sint√©tico com caracter√≠sticas similares, salvando o resultado como `heart.csv`.

A an√°lise dos algoritmos foi integrada diretamente na aplica√ß√£o web (`app.py`):

1.  Na barra lateral, selecione a op√ß√£o **"An√°lise de Doen√ßas Card√≠acas (Quest√£o 3)"**.
2.  Ao clicar no bot√£o para executar, a aplica√ß√£o carrega o `heart.csv`.
3.  Um modelo de √Årvore de Decis√£o (usando Scikit-learn) e um modelo **RIPPER** (usando a biblioteca `wittgenstein`) s√£o treinados e avaliados.
4.  Os resultados, incluindo acur√°cia, relat√≥rio de classifica√ß√£o e o conjunto de regras gerado pelo RIPPER, s√£o exibidos lado a lado para compara√ß√£o.

### Resultados e An√°lise

A aplica√ß√£o apresenta de forma interativa os resultados da √Årvore de Decis√£o e do RIPPER. O principal destaque √© a exibi√ß√£o din√¢mica do conjunto de regras gerado pelo RIPPER, que permite uma an√°lise direta de sua simplicidade e interpretabilidade. Em geral, as regras do RIPPER s√£o mais concisas e f√°ceis de entender do que a estrutura completa de uma √°rvore de decis√£o, ilustrando a principal vantagem dos algoritmos de extra√ß√£o de regras.

---

## Quest√µes 4 & 5 ‚Äî Overfitting, Underfitting e o papel do C4.5

### Defini√ß√µes

* **Overfitting (sobreajuste):** modelo que ajusta o ru√≠do dos dados de treino. Alto desempenho no treino; baixa generaliza√ß√£o no teste.

  *Analogia did√°tica:* aluno que decora respostas espec√≠ficas da lista, mas n√£o resolve problemas novos.

* **Underfitting (subajuste):** modelo demasiado simples; n√£o captura a estrutura dos dados. Performance ruim em treino e teste.

  *Analogia:* aluno que n√£o estudou o conte√∫do.

### Como C4.5 ajuda?

* **Poda p√≥s-crescimento (pessimistic pruning):** cresce √°rvore at√© pureza e depois poda n√≥s que n√£o reduzem o erro esperado ‚Äî troca complexidade por generaliza√ß√£o.

* **Melhor tratamento de atributos cont√≠nuos:** ponto de corte √∫nico e estatisticamente justificado.

* **Crit√©rios de parada / m√≠nimos:** evita divis√µes em n√≥s com poucos exemplos (reduz regras esp√∫rias).

### Demonstra√ß√£o Pr√°tica com kNN

Para al√©m da discuss√£o te√≥rica, foi implementada uma an√°lise pr√°tica na aplica√ß√£o web (`app.py`) para visualizar os fen√¥menos de overfitting e underfitting. Na se√ß√£o expans√≠vel **"üî¨ An√°lise de Overfitting/Underfitting com kNN"**, √© poss√≠vel executar o algoritmo kNN no dataset de doen√ßas card√≠acas com uma faixa de valores para o hiperpar√¢metro *k*.

A aplica√ß√£o gera um gr√°fico interativo que plota a acur√°cia do modelo em fun√ß√£o de *k*. Este gr√°fico demonstra empiricamente que:

*   **Valores de *k* muito baixos** (e.g., k=1) tendem a ter uma acur√°cia vol√°til e podem se ajustar demais aos ru√≠dos dos dados de treino (**overfitting**).
*   **Valores de *k* muito altos** suavizam demais a fronteira de decis√£o, fazendo o modelo perder a capacidade de capturar a complexidade dos dados e resultando em queda de performance (**underfitting**).
*   O valor √≥timo de *k*, que maximiza a acur√°cia no conjunto de teste, representa o melhor equil√≠brio (bias-variance tradeoff) para este dataset.

---

## Quest√£o 6 ‚Äî k-Nearest Neighbors (kNN)

### (a) Exemplo num√©rico (k = 1, 3, 7)

**Dataset (x (renda em x1000), y (idade)):**

```
P1 (50,30) ‚Äî A
P2 (80,40) ‚Äî B
P3 (90,35) ‚Äî B
P4 (40,25) ‚Äî A
P5 (85,45) ‚Äî B
P6 (60,35) ‚Äî A
P? (70,30) ‚Äî ? (a classificar)
```

**Dist√¢ncias euclidianas (c√°lculo passo a passo):**

* d(P?,P1) = sqrt((70‚àí50)¬≤ + (30‚àí30)¬≤) = sqrt(400+0) = 20.00
* d(P?,P2) = sqrt((70‚àí80)¬≤ + (30‚àí40)¬≤) = sqrt(100+100) ‚âà 14.142 ‚Üí 14.14
* d(P?,P3) = sqrt((70‚àí90)¬≤ + (30‚àí35)¬≤) = sqrt(400+25) ‚âà 20.616 ‚Üí 20.61
* d(P?,P4) = sqrt((70‚àí40)¬≤ + (30‚àí25)¬≤) = sqrt(900+25) ‚âà 30.414 ‚Üí 30.41
* d(P?,P5) = sqrt((70‚àí85)¬≤ + (30‚àí45)¬≤) = sqrt(225+225) ‚âà 21.213 ‚Üí 21.21
* d(P?,P6) = sqrt((70‚àí60)¬≤ + (30‚àí35)¬≤) = sqrt(100+25) ‚âà 11.180 ‚Üí 11.18

**Ordena√ß√£o (mais pr√≥ximo ‚Üí mais distante):** P6, P2, P1, P3, P5, P4

* `k=1` ‚Üí vizinho: P6 (A) ‚Üí **A**
* `k=3` ‚Üí vizinhos: P6 (A), P2 (B), P1 (A) ‚Üí vota√ß√£o (A:2, B:1) ‚Üí **A**
* `k=7` (aqui n=6 ‚Üí k=6): empate A:3 vs B:3 ‚Üí estrat√©gias: desempate por soma/ m√©dia de dist√¢ncias ou reduzir k (ex.: k √≠mpar)

### (b) Como escolher k

* *Regra-de-polegar:* k ‚âà ‚àöN (N = n¬∫ amostras).
* *Melhor pr√°tica:* valida√ß√£o cruzada para testar v√°rios k e escolher o que maximiza a m√©trica de interesse.

### (c) Falhas da dist√¢ncia Euclidiana e alternativa (Gower)

* **Problema:** atributos com escalas diferentes e dados mistos (num√©rico + categ√≥rico).
* **Alternativa recomendada para dados mistos:** *Dist√¢ncia de Gower* ‚Äî normaliza num√©ricos (por range) e usa 0/1 para categ√≥ricos; soma ponderada d√° a dist√¢ncia final.

Exemplo Gower (Renda em R\$):

* `|50000 ‚àí 51000| / range = 1000 / 100000 = 0.01`
* Estado civil diferente ‚Üí dist√¢ncia categ√≥rica = 1
* Gower m√©dia = (0.01 + 1) / 2 = 0.505

### (d) Cen√°rios onde kNN √© ineficaz

* Alta dimensionalidade (a vizinhan√ßa perde sentido).
* Conjuntos de treino muito grandes (previs√µes custosas).
* Classes fortemente desbalanceadas.
* Dados mistos sem uso de dist√¢ncias apropriadas.

### (e) Lazy vs Eager

* **kNN:** *lazy* ‚Äî quase nenhum treino, custo na predi√ß√£o.
* **√Årvores/SVM:** *eager* ‚Äî treino caro, predi√ß√£o r√°pida.

### Implementa√ß√£o e An√°lise Pr√°tica

A implementa√ß√£o pr√°tica deste algoritmo foi realizada em `knn_classifier.py` e integrada √† aplica√ß√£o principal de duas formas distintas:

1.  Um **exemplo did√°tico** na se√ß√£o "Explorador k-Nearest Neighbors", que permite classificar um √∫nico ponto novo em um dataset 2D, visualizando os vizinhos mais pr√≥ximos.
2.  Uma **an√°lise de sensibilidade do hiperpar√¢metro *k***, conforme descrito na se√ß√£o anterior (Quest√µes 4 & 5), que utiliza o dataset de doen√ßas card√≠acas para uma explora√ß√£o mais robusta do comportamento do algoritmo e para demonstrar visualmente os conceitos de overfitting e underfitting.

---

## Reprodutibilidade, limita√ß√µes e notas metodol√≥gicas

* **C√°lculos manuais:** realizados em papel; os scans/fotos est√£o em `sodeusnacausa/`. 
* **Pr√©-processamento:** LabelEncoding foi usado para simplicidade did√°tica. Em aplica√ß√µes reais, possivelmente utilizar√≠amos `OneHotEncoding` e normaliza√ß√£o, que √© importante.