<p align="center">
  <img src="https://ufal.br/ufal/comunicacao/identidade-visual/brasao/ods/ufal_ods1.png" alt="Logo UFAL" width="320"/>
</p>



<h1 align="center">
  Lista de ExercÃ­cios â€” Aprendizagem de MÃ¡quina<br>
  Mestrado em InformÃ¡tica â€” UFAL
</h1>

<p align="center">
  <b>Disciplina:</b> Aprendizagem de MÃ¡quina<br>
  <b>Professor:</b> Evandro de Barros Costa (<a href="mailto:evandro@ic.ufal.br">evandro@ic.ufal.br</a>)<br>
  <b>Departamento:</b> Instituto de ComputaÃ§Ã£o â€” UFAL<br>
  <b>Lattes:</b> <a href="http://lattes.cnpq.br/5760364940162939">http://lattes.cnpq.br/5760364940162939</a>
</p>

<p align="center">
  <b>Autor:</b> FÃ¡bio Linhares<br>
  <b>Lattes:</b> <a href="http://lattes.cnpq.br/7908261028551208">http://lattes.cnpq.br/7908261028551208</a>
</p>

<p align="center">
  <a href="https://tutu.zerocopia.com.br/" target="_blank">
    <img src="https://img.shields.io/badge/Acessar%20AplicaÃ§Ã£o-Streamlit-FF4B4B?style=for-the-badge&logo=streamlit" alt="Streamlit App">
  </a>
</p>

<p align="center">
  <i>Este trabalho integra as atividades da disciplina de Aprendizagem de MÃ¡quina do Programa de PÃ³s-GraduaÃ§Ã£o em InformÃ¡tica (Mestrado), Universidade Federal de Alagoas.</i>
</p>

<div style="text-align: justify;">

# Lista de ExercÃ­cios 1

**Resumo:** ResoluÃ§Ã£o completa, questÃ£o a questÃ£o, com cÃ³digo, resultados e material de suporte (prints dos cÃ¡lculos manuais). Este README descreve a estrutura do repositÃ³rio, como reproduzir os experimentos, as decisÃµes metodolÃ³gicas, resultados-chave e observaÃ§Ãµes crÃ­ticas.

</div>

---

## Ãndice

1. [Estrutura do repositÃ³rio](#estrutura-do-repositÃ³rio)
2. [Como replicar (quickstart)](#como-replicar-quickstart)
3. [Dados (`clientes.csv`)](#dados-clientescsv)
4. [QuestÃ£o 1 â€” ExpansÃ£o da base e construÃ§Ã£o manual de Ã¡rvores](#questÃ£o-1---expansÃ£o-da-base-e-construÃ§Ã£o-manual-de-Ã¡rvores)
5. [QuestÃ£o 2 â€” ImplementaÃ§Ã£o com bibliotecas (Scikit-learn) e cÃ³digo prÃ³prio](#questÃ£o-2---implementaÃ§Ã£o-com-bibliotecas-scikit-learn-e-cÃ³digo-prÃ³prio)
6. [QuestÃ£o 3 â€” Dataset do Kaggle (Heart Disease) e regras diretas (RIPPER)](#questÃ£o-3---dataset-do-kaggle-heart-disease-e-regras-diretas-ripper)
7. [QuestÃµes 4 & 5 â€” Overfitting, Underfitting e o papel do C4.5](#questÃµes-4--5---overfitting-underfitting-e-o-papel-do-c45)
8. [QuestÃ£o 6 â€” k-Nearest Neighbors (kNN): explicaÃ§Ã£o, exemplo numÃ©rico e limitaÃ§Ãµes](#questÃ£o-6---k%E2%80%8Bnearest-neighbors-knn-explicaÃ§Ã£o-exemplo-numÃ©rico-e-limitaÃ§Ãµes)
9. [Reprodutibilidade, limitaÃ§Ãµes e notas metodolÃ³gicas](#reprodutibilidade-limitaÃ§Ãµes-e-notas-metodolÃ³gicas)
10. [ContribuiÃ§Ãµes, contato e licenÃ§a](#contribuiÃ§Ãµes-contato-e-licenÃ§a)

---

## Estrutura do repositÃ³rio

```
.
â”œâ”€â”€ app.py                     # AplicaÃ§Ã£o web interativa com Streamlit
â”œâ”€â”€ backup/                    # Arquivos de backup de versÃµes anteriores
â”œâ”€â”€ class_cart.py              # Classe wrapper para o algoritmo CART
â”œâ”€â”€ class_c45.py               # Classe wrapper para o algoritmo C4.5
â”œâ”€â”€ class_id3.py               # Classe wrapper para o algoritmo ID3
â”œâ”€â”€ clientes.csv               # Base de dados expandida (30 instÃ¢ncias) - QuestÃ£o 1
â”œâ”€â”€ heart.csv                  # Base de dados do Kaggle - QuestÃ£o 3
â”œâ”€â”€ download_heart_dataset.py  # Script para baixar o dataset da QuestÃ£o 3
â”œâ”€â”€ evaluate_models.py         # Script para avaliaÃ§Ã£o dos modelos (mÃ©tricas e matrizes)
â”œâ”€â”€ heart_disease_ripper.py    # ImplementaÃ§Ã£o da anÃ¡lise com RIPPER (QuestÃ£o 3)
â”œâ”€â”€ knn_classifier.py          # ImplementaÃ§Ã£o do classificador kNN (QuestÃ£o 6)
â”œâ”€â”€ optimized_tree.py          # NÃºcleo otimizado que implementa a lÃ³gica das Ã¡rvores
â”œâ”€â”€ README.md                  # Este arquivo de documentaÃ§Ã£o
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â”œâ”€â”€ resultados_img/            # Imagens das matrizes de confusÃ£o e das Ã¡rvores de decisÃ£o
â”‚   â”œâ”€â”€ c45.PNG
â”‚   â”œâ”€â”€ cart.PNG
â”‚   â”œâ”€â”€ id3.PNG
â”‚   â”œâ”€â”€ matriz_confusao_c4.5.png
â”‚   â”œâ”€â”€ matriz_confusao_cart.png
â”‚   â””â”€â”€ matriz_confusao_id3.png
â””â”€â”€ sodeusnacausa/             # Screenshots com os cÃ¡lculos manuais (QuestÃ£o 1)
```

---

<div style="text-align: justify;">

## InstalaÃ§Ã£o e ExecuÃ§Ã£o

Recomendamos a criaÃ§Ã£o de um ambiente virtual para isolar as dependÃªncias do projeto.
Ainda assim, vocÃª tem total liberdade para adotar o procedimento que considerar mais conveniente. Nossa orientaÃ§Ã£o contempla duas opÃ§Ãµes bastante utilizadas no mercado: **venv** â€“ ferramenta nativa e padrÃ£o do Python para criaÃ§Ã£o de ambientes virtuais, simples e leve ou **Miniconda** â€“ uma versÃ£o reduzida do Anaconda, que inclui o gerenciador de pacotes Conda sem trazer, por padrÃ£o, o conjunto extenso de bibliotecas prÃ©-instaladas.

### 1. CriaÃ§Ã£o do Ambiente Virtual
**Usando venv** : cria um ambiente isolado em uma pasta chamada `venv`:

```bash
python -m venv venv
```

**Usando Miniconda**: cria um ambiente isolado chamado `lista1_ml` com uma versÃ£o especÃ­fica do Python:

```bash
conda create --name lista1_ml python=3.12
```

---

### 2. AtivaÃ§Ã£o e DesativaÃ§Ã£o do Ambiente

Ã‰ crucial ativar o ambiente antes de instalar pacotes ou executar a aplicaÃ§Ã£o.

**Com venv**

Para ativar:

```bash
# No Linux ou macOS
source venv/bin/activate

# No Windows (PowerShell)
.\venv\Scripts\Activate.ps1
```

Para desativar:

```bash
deactivate
```

**Com Miniconda**

Para ativar:

```bash
conda activate lista1_ml
```

Para desativar:

```bash
conda deactivate
```

---

### 3. InstalaÃ§Ã£o das DependÃªncias

Com o ambiente devidamente ativado, instale todos os pacotes necessÃ¡rios:

```bash
pip install -r requirements.txt
```

---

### 4. Executando a AplicaÃ§Ã£o

Para iniciar o servidor do Streamlit e visualizar a aplicaÃ§Ã£o, execute:

```bash
streamlit run app.py 
# acesse http://localhost:8501
```
---

## QuestÃ£o 1 â€” ExpansÃ£o da base e construÃ§Ã£o manual de Ã¡rvores

### Objetivos

1. Expandir a base original para 30 exemplos.
2. Construir manualmente trÃªs Ã¡rvores: **ID3**, **C4.5** e **CART**, mostrando cÃ¡lculos.
3. Extrair regras `SE ... ENTÃƒO`.
4. Comparar e recomendar a melhor base de regras.

## Base de Dados

**DescriÃ§Ã£o**


A primeira questÃ£o da lista de exercÃ­cios solicitava que, a partir de uma base fornecida pelo â€œgerente do bancoâ€ fosse realizada uma ampliaÃ§Ã£o para que contivesse 6 atributos e 30 exemplos divididos entre as classes de Risco Baixo, Moderado e Alto. Como a referida base continha apenas 14 instÃ¢ncias, fizemos a adiÃ§Ã£o de 16, distribuÃ­das entre as classes solicitadas, mantendo a coerÃªncia com os dados originais. A base final, disponÃ­vel no arquivo `clientes.csv`, possui as seguintes caracterÃ­sticas:

* 30 instÃ¢ncias
* 6 atributos (Renda, HistÃ³ria de CrÃ©dito, Garantia, Idade, Tipo de Emprego e Risco)
* Target/Classe: `Risco` com trÃªs nÃ­veis: `Baixo`, `Moderado` e `Alto`.

**DistribuiÃ§Ã£o de classes**

* Baixo Risco: 12
* Moderado Risco: 8
* Alto Risco: 10
* Total: 30

> ObservaÃ§Ã£o: o arquivo `clientes.csv` foi usado em todas as anÃ¡lises deste exercÃ­cio.

---


### Metodologia e fÃ³rmulas utilizadas

* **Entropia:** `Entropy(S) = - Î£ p_i log2(p_i)`
* **Ganho de InformaÃ§Ã£o (ID3/C4.5):** `Gain(S, A) = Entropy(S) - Î£ (|S_v|/|S|) Entropy(S_v)`
* **Ãndice Gini (CART):** `Gini(S) = 1 - Î£ p_i^2`

### CÃ¡lculo do nÃ³ raiz

* `p_Baixo = 12/30`, `p_Moderado = 8/30`, `p_Alto = 10/30`

* **Entropia (raiz, ID3/C4.5):**

  ```
  Entropy(S) = -[ (12/30)log2(12/30) + (8/30)log2(8/30) + (10/30)log2(10/30) ] â‰ˆ 1.565
  ```
* **Gini (raiz, CART):**

  ```
  Gini(S) = 1 - [ (12/30)^2 + (8/30)^2 + (10/30)^2 ] â‰ˆ 0.658
  ```

> Os cÃ¡lculos completos (passo a passo) foram feitos em papel e os prints estÃ£o em `sodeusnacausa/` .

### Ãrvores finais

**ID3**

```
      [ Renda ]
     /    |    \
 ($0-$15k) ($15-$35k) (> $35k)
    |         |          \
 [Hist. Cred] [Hist. Cred] [ Baixo ]
  /  |   \       /   |   \
(R) (D)  (B)   (R) (D) (B)
 |   |    |     |   |   |
[A] [A] [Garantia] [A] [M] [M]
    /    \
  (N)    (AD)
   |      |
  [A]    [M]


Legenda: R=Ruim, D=Desconhecida, B=Boa, N=Nenhuma, AD=Adequada, A=Alto, M=Moderado
```

**C4.5** (semelhante ao ID3, mas com cortes contÃ­nuos)

```
         [Renda]
        /   |    \
  $0-15k $15-35k  >$35k
   |       |        \
 [Alto] [Idade <= 32.5] [Baixo]
```

**CART**

```
  [ Renda = '$0-$15k'? ]
  /                   \
    Sim                    Nao
     |                      |
   [ Alto ]        [ Renda = '> $35k'? ]
       /                  \
         Sim                   Nao
      |                     |
        [ Baixo ]      [ Hist. Cred = 'Ruim'? ]
            /                     \
          Sim                      Nao
           |                        |
             [ Alto ]                [ Moderado ]
```

### Regras extraÃ­das

> ObservaÃ§Ã£o: em aula eu comentei que nÃ£o recordava a ocorrencia de over e underfitting em Ã¡rvores de decisÃ£o. ApÃ³s a realizaÃ§Ã£o destes exercÃ­cios percebi que o overfitting esta mais relacionados Ã s Ã¡rvores nÃ£o podadas (como ID3 puro). JÃ¡ o underfitting, que Ã© menos comum, e talvez isso justifique minha falta de memÃ³ria, pode ocorrer se a Ã¡rvore for excessivamente simplificada ou se os dados forem muito ruidosos.

#### **Regras da Ãrvore ID3**
- **R1:** SE Renda = '$0 a $15k' E HistÃ³ria de CrÃ©dito = 'Ruim' ENTÃƒO Risco = 'Alto' (Suporte=3, AcurÃ¡cia=100%)
- **R2:** SE Renda = '$0 a $15k' E HistÃ³ria de CrÃ©dito = 'Desconhecida' ENTÃƒO Risco = 'Alto' (Suporte=3, AcurÃ¡cia=100%)
- **R3:** SE Renda = '$0 a $15k' E HistÃ³ria de CrÃ©dito = 'Boa' E Garantia = 'Nenhuma' ENTÃƒO Risco = 'Alto' (Suporte=1, AcurÃ¡cia=100%)
- **R4:** SE Renda = '$0 a $15k' E HistÃ³ria de CrÃ©dito = 'Boa' E Garantia = 'Adequada' ENTÃƒO Risco = 'Moderado' (Suporte=1, AcurÃ¡cia=100%)
- **R5:** SE Renda = '$15 a $35k' E HistÃ³ria de CrÃ©dito = 'Ruim' ENTÃƒO Risco = 'Alto' (Suporte=2, AcurÃ¡cia=100%)
- **R6:** SE Renda = '$15 a $35k' E HistÃ³ria de CrÃ©dito = 'Desconhecida' ENTÃƒO Risco = 'Moderado' (Suporte=1, AcurÃ¡cia=100%)
- **R7:** SE Renda = '$15 a $35k' E HistÃ³ria de CrÃ©dito = 'Boa' ENTÃƒO Risco = 'Moderado' (Suporte=4, AcurÃ¡cia=50%)
- **R8:** SE Renda = 'Acima de $35k' ENTÃƒO Risco = 'Baixo' (Suporte=13, AcurÃ¡cia=76,9%)

#### **Regras da Ãrvore C4.5**
- **R1:** SE Renda = '$0 a $15k' ENTÃƒO Risco = 'Alto' (Suporte=8, AcurÃ¡cia=87,5%)
- **R2:** SE Renda = '$15 a $35k' E Idade <= 30.5 E HistÃ³ria de CrÃ©dito = 'Desconhecida' ENTÃƒO Risco = 'Moderado' (Suporte=1, AcurÃ¡cia=100%)
- *(Demais ramos seguem lÃ³gica semelhante, com regras mais gerais devido Ã  poda.)*

#### **Regras da Ãrvore CART**
- **R1:** SE Renda = '$0 a $15k' ENTÃƒO Risco = 'Alto' (Suporte=8, AcurÃ¡cia=87,5%)
- **R2:** SE Renda != '$0 a $15k' E Renda = 'Acima de $35k' ENTÃƒO Risco = 'Baixo' (Suporte=13, AcurÃ¡cia=76,9%)
- **R3:** SE Renda != '$0 a $15k' E Renda != 'Acima de $35k' E HistÃ³ria de CrÃ©dito = 'Ruim' ENTÃƒO Risco = 'Alto' (Suporte=2, AcurÃ¡cia=100%)
- **R4:** SE Renda != '$0 a $15k' E Renda != 'Acima de $35k' E HistÃ³ria de CrÃ©dito != 'Ruim' ENTÃƒO Risco = 'Moderado' (Suporte=7, AcurÃ¡cia=71,4%)

---

### (iv) ComparaÃ§Ã£o e SeleÃ§Ã£o da Base de Regras

| CritÃ©rio           | ID3                                         | C4.5                                  | CART                                 |
|--------------------|---------------------------------------------|---------------------------------------|--------------------------------------|
| **Simplicidade**   | Muitas regras, algumas muito especÃ­ficas    | Menos regras, mais gerais (poda)      | Poucas regras, estrutura binÃ¡ria     |
| **ExatidÃ£o (Treino)** | Alta (tende a overfit)                  | Alta, controlada por poda             | Boa, balanceada                      |
| **Interpretabilidade** | Moderada, granularidade pode confundir | Boa                                   | Excelente, lÃ³gica binÃ¡ria clara      |
| **Robustez**       | Baixa (sensÃ­vel a ruÃ­do)                   | MÃ©dia (poda ajuda)                    | MÃ©dia                                |

**ReflexÃ£o:**

A base de regras do CART Ã© a mais concisa (4 regras) e possui estrutura binÃ¡ria de fÃ¡cil interpretaÃ§Ã£o. As regras cobrem todos os casos de forma mutuamente exclusiva. O ID3 gera muitas regras muito especÃ­ficas, sugerindo overfitting. Sinceramene, preferimos o CART pela simplicidade e clareza, **principalmente porque tivemos que fazer a mÃ£o**, embora tais caracterÃ­stias sejam em essencia, fundamentais em sistemas de apoio Ã  decisÃ£o. A regra "SE Renda Ã© alta, ENTÃƒO Risco Ã© Baixo" Ã© intuitiva. A leve perda de acurÃ¡cia Ã© compensada pela interpretabilidade. De modo geral, pareceu-nos que modelos mais simples (C4.5 podado ou CART) tendem a generalizar melhor e, por conta disso, serem preferÃ­veis em domÃ­nios onde interpretabilidade Ã© crÃ­tica, como na Ã¡rea de finanÃ§as, por exemplo.


---

## QuestÃ£o 2 â€” ImplementaÃ§Ã£o com bibliotecas (Scikit-learn) e cÃ³digo prÃ³prio

### Arquitetura do CÃ³digo

A implementaÃ§Ã£o foi refatorada para uma arquitetura mais robusta e modular:

*   **`optimized_tree.py`**: Atua como o **cÃ©rebro** do sistema. ContÃ©m a classe `OptimizedDecisionTree`, que implementa toda a lÃ³gica de construÃ§Ã£o de Ã¡rvores, incluindo os cÃ¡lculos de mÃ©tricas (Entropia, Gini, Gain Ratio), divisÃµes de dados (categÃ³ricos e contÃ­nuos) e a estrutura da Ã¡rvore. Ele Ã© projetado para ser configurÃ¡vel e atender aos requisitos especÃ­ficos de cada algoritmo (ID3, C4.5 e CART).
*   **`class_id3.py`, `class_c45.py`, `class_cart.py`**: Funcionam como **wrappers** ou "fachadas". Cada classe simplesmente instancia o motor `OptimizedDecisionTree` com a configuraÃ§Ã£o correta (`algorithm='id3'`, `'c45'` ou `'cart'`). Isso elimina a duplicaÃ§Ã£o de cÃ³digo e centraliza a lÃ³gica de decisÃ£o em um Ãºnico local, facilitando a manutenÃ§Ã£o e a comparaÃ§Ã£o.

### AnÃ¡lise das DivergÃªncias: Manual vs. CÃ³digo

Ao comparar as Ã¡rvores geradas manualmente na questÃ£o anterior com as produzidas  nessa implementaÃ§Ã£o Ã© possÃ­vel notar divergÃªncias. Essas diferenÃ§as nÃ£o indicam um erro, mas sim destacam a natureza da implementaÃ§Ã£o computacional em contraste com a abordagem manual. As principais razÃµes para isso sÃ£o:

1.  **PrecisÃ£o e CritÃ©rios de Desempate:** Os cÃ¡lculos manuais frequentemente envolvem arredondamentos. O cÃ³digo, por outro lado, trabalha com a precisÃ£o total de ponto flutuante. Uma diferenÃ§a mÃ­nima no ganho de informaÃ§Ã£o ou no Ã­ndice Gini, invisÃ­vel manualmente, pode levar o algoritmo a escolher um atributo diferente. AlÃ©m disso, em caso de empate, o cÃ³digo seguirÃ¡ uma lÃ³gica determinÃ­stica (ex: escolher o primeiro atributo da lista), enquanto a escolha manual pode ser arbitrÃ¡ria.

2.  **Tratamento Exaustivo dos Atributos:**
    *   **Atributos ContÃ­nuos (C4.5/CART):** O cÃ³digo testa sistematicamente todos os pontos de corte possÃ­veis entre valores Ãºnicos e ordenados para encontrar o limiar que maximiza a mÃ©trica de divisÃ£o. Manualmente, Ã© impraticÃ¡vel realizar essa busca exaustiva.
    *   **Atributos CategÃ³ricos (CART):** Para criar uma divisÃ£o binÃ¡ria, o algoritmo testa todas as combinaÃ§Ãµes de "um valor vs. o resto", garantindo a escolha Ã³tima, algo que pode passar despercebido na anÃ¡lise manual.

3.  **Impacto de HiperparÃ¢metros e GeneralizaÃ§Ã£o:** A implementaÃ§Ã£o em cÃ³digo utiliza hiperparÃ¢metros como `max_depth` para controlar a complexidade da Ã¡rvore. Isso Ã© uma tÃ©cnica fundamental para evitar o *overfitting* (sobreajuste), resultando em Ã¡rvores potencialmente menores e com maior poder de generalizaÃ§Ã£o. As Ã¡rvores manuais, especialmente a do ID3, foram construÃ­das atÃ© a pureza total dos ramos, criando regras muito especÃ­ficas que podem nÃ£o performar bem com dados novos.

Em suma, a Ã¡rvore gerada pelo cÃ³digo Ã© o resultado de um processo mais rigoroso, reproduzÃ­vel e alinhado com as boas prÃ¡ticas de aprendizado de mÃ¡quina, que priorizam a generalizaÃ§Ã£o em detrimento do ajuste perfeito aos dados de treino.

### Resultados de Desempenho (Treinamento)

O sistema de memoizaÃ§Ã£o (`AdvancedMemoizationTable`) implementado em `optimized_tree.py` armazena em cache os resultados de cÃ¡lculos repetitivos (como Entropia e Gini para o mesmo subconjunto de dados). Isso acelera significativamente o treinamento, especialmente em Ã¡rvores mais profundas.

Abaixo estÃ£o os resultados de uma execuÃ§Ã£o tÃ­pica, mostrando o tempo de treinamento e a eficiÃªncia do cache:

| Algoritmo | Tempo de Treinamento | Taxa de Acerto do Cache |
| :-------- | :------------------- | :---------------------- |
| **ID3**   | ~0.275s              | ~42.7%                  |
| **C4.5**  | ~0.223s              | ~63.0%                  |
| **CART**  | ~0.299s              | ~67.4%                  |

*ObservaÃ§Ã£o: Os tempos podem variar ligeiramente a cada execuÃ§Ã£o. A alta taxa de acerto do cache, especialmente para C4.5 e CART, demonstra a eficÃ¡cia da otimizaÃ§Ã£o, pois muitos nÃ³s da Ã¡rvore avaliam os mesmos subconjuntos de dados repetidamente.*

### ObservaÃ§Ãµes tÃ©cnicas

*   `scikit-learn` produz Ã¡rvores binÃ¡rias por padrÃ£o (CART) e faz otimizaÃ§Ãµes que reduzem overfitting aparente (ex.: parÃ¢metros `min_samples_split`, `max_depth`, etc.).
*   Nossa implementaÃ§Ã£o agora reflete essa sofisticaÃ§Ã£o, com um motor central que lida com as nuances de cada algoritmo, tornando a comparaÃ§Ã£o mais direta e o cÃ³digo mais limpo.

### AvaliaÃ§Ã£o dos Modelos e AnÃ¡lise de Resultados

Para avaliar o desempenho de cada algoritmo, dividimos o dataset em 70% para treino e 30% para teste. O script `evaluate_models.py` foi executado para treinar os modelos e gerar as mÃ©tricas e visualizaÃ§Ãµes a seguir.

#### MÃ©tricas de Desempenho Comparativas

A tabela abaixo resume o desempenho de cada modelo no conjunto de teste:

| MÃ©trica         | ID3     | C4.5    | CART    |
| :-------------- | :------ | :------ | :------ |
| **AcurÃ¡cia**    | 77.78%  | 77.78%  | 77.78%  |
| **PrecisÃ£o**    | 0.80    | 0.61    | 0.80    |
| **Recall**      | 0.78    | 0.78    | 0.78    |
| **F1-Score**    | 0.77    | 0.68    | 0.77    |

*Nota: PrecisÃ£o, Recall e F1-Score sÃ£o mÃ©dias ponderadas.*

#### Matrizes de ConfusÃ£o

As matrizes de confusÃ£o detalham os acertos e erros de cada modelo por classe.

<div style="display: flex; justify-content: center; gap: 32px; align-items: flex-start;">

<div style="text-align: center;">
  <strong>ID3</strong><br>
  <img src="resultados_img/matriz_confusao_id3.png" alt="Matriz de ConfusÃ£o ID3" width="320"/>
</div>

<div style="text-align: center;">
  <strong>C4.5</strong><br>
  <img src="resultados_img/matriz_confusao_c4.5.png" alt="Matriz de ConfusÃ£o C4.5" width="320"/>
</div>

<div style="text-align: center;">
  <strong>CART</strong><br>
  <img src="resultados_img/matriz_confusao_cart.png" alt="Matriz de ConfusÃ£o CART" width="320"/>
</div>

</div>

#### AnÃ¡lise das Matrizes

1.  **AcurÃ¡cia Geral:** Todos os trÃªs modelos alcanÃ§aram a mesma acurÃ¡cia de **77.78%** no conjunto de teste, acertando 7 das 9 instÃ¢ncias. Isso sugere que, para este dataset e com a profundidade de Ã¡rvore limitada (`max_depth=5`), o poder preditivo dos trÃªs algoritmos Ã© bastante similar.

2.  **Desempenho do ID3 e CART:** Os modelos ID3 e CART apresentaram um comportamento idÃªntico, conforme suas matrizes de confusÃ£o. Ambos classificaram perfeitamente a classe `Baixo` Risco (4/4 acertos). No entanto, tiveram dificuldade com as outras classes: erraram 1 das 3 instÃ¢ncias de `Alto` Risco (classificando-a como `Baixo`) e 1 das 2 de `Moderado` Risco (classificando-a como `Alto`). Isso resultou em uma precisÃ£o mais baixa para a classe `Moderado` (50%).

3.  **Desempenho do C4.5:** O modelo C4.5 se destacou por classificar perfeitamente tanto a classe `Alto` (3/3) quanto a `Baixo` (4/4). Seu ponto fraco foi a classe `Moderado`, que ele **nÃ£o conseguiu identificar corretamente nenhuma vez**, classificando as duas instÃ¢ncias como `Alto`. Isso explica por que sua precisÃ£o geral ponderada (0.61) Ã© significativamente menor que a dos outros modelos, apesar da mesma acurÃ¡cia. O C4.5, neste caso, criou regras que generalizaram demais a classe `Moderado`, absorvendo-a na `Alto`.

**ConclusÃ£o da AnÃ¡lise:** Embora a acurÃ¡cia seja a mesma, os modelos **ID3 e CART** mostram um comportamento mais equilibrado, sendo capazes de identificar, ainda que com alguns erros, todas as trÃªs classes. O **C4.5** demonstrou uma tendÃªncia a "ignorar" a classe minoritÃ¡ria (`Moderado`) em favor das outras, o que pode ser um comportamento indesejado em problemas onde a detecÃ§Ã£o de todas as classes Ã© crÃ­tica.

#### VisualizaÃ§Ã£o das Ãrvores de DecisÃ£o


<div style="display: flex; justify-content: center; gap: 32px; align-items: flex-start;">

<div style="text-align: center;">
  <strong>ID3</strong><br>
  <img src="resultados_img/id3.PNG" alt="Ãrvore de DecisÃ£o ID3" width="380"/>
</div>

<div style="text-align: center;">
  <strong>C4.5</strong><br>
  <img src="resultados_img/c45.PNG" alt="Ãrvore de DecisÃ£o C4.5" width="380"/>
</div>

<div style="text-align: center;">
  <strong>CART</strong><br>
  <img src="resultados_img/cart.PNG" alt="Ãrvore de DecisÃ£o CART" width="380"/>
</div>

</div>


---

## QuestÃ£o 3 â€” Dataset do Kaggle (Heart Disease) e regras diretas (RIPPER)

### Dataset escolhido

* **Heart Disease UCI** â€” conjunto clÃ¡ssico, alvo binÃ¡rio (`target`), mistura de variÃ¡veis contÃ­nuas e categÃ³ricas.

### Procedimento e ImplementaÃ§Ã£o

Para resolver a dependÃªncia do dataset, foi criado o script `download_heart_dataset.py`. Ao ser executado, ele baixa o conjunto de dados "Heart Disease UCI" do repositÃ³rio OpenML ou, em caso de falha, gera um dataset sintÃ©tico com caracterÃ­sticas similares, salvando o resultado como `heart.csv`.

A anÃ¡lise dos algoritmos foi integrada diretamente na aplicaÃ§Ã£o web (`app.py`):

1.  Na barra lateral, selecione a opÃ§Ã£o **"AnÃ¡lise de DoenÃ§as CardÃ­acas (QuestÃ£o 3)"**.
2.  Ao clicar no botÃ£o para executar, a aplicaÃ§Ã£o carrega o `heart.csv`.
3.  Um modelo de Ãrvore de DecisÃ£o (usando Scikit-learn) e um modelo **RIPPER** (usando a biblioteca `wittgenstein`) sÃ£o treinados e avaliados.
4.  Os resultados, incluindo acurÃ¡cia, relatÃ³rio de classificaÃ§Ã£o e o conjunto de regras gerado pelo RIPPER, sÃ£o exibidos lado a lado para comparaÃ§Ã£o.

### Resultados e AnÃ¡lise

A aplicaÃ§Ã£o apresenta de forma interativa os resultados da Ãrvore de DecisÃ£o e do RIPPER. O principal destaque Ã© a exibiÃ§Ã£o dinÃ¢mica do conjunto de regras gerado pelo RIPPER, que permite uma anÃ¡lise direta de sua simplicidade e interpretabilidade. Em geral, as regras do RIPPER sÃ£o mais concisas e fÃ¡ceis de entender do que a estrutura completa de uma Ã¡rvore de decisÃ£o, ilustrando a principal vantagem dos algoritmos de extraÃ§Ã£o de regras.

---

## QuestÃµes 4 & 5 â€” Overfitting, Underfitting e o papel do C4.5

### DefiniÃ§Ãµes

* **Overfitting (sobreajuste):** modelo que ajusta o ruÃ­do dos dados de treino. Alto desempenho no treino; baixa generalizaÃ§Ã£o no teste.

  *Analogia didÃ¡tica:* aluno que decora respostas especÃ­ficas da lista, mas nÃ£o resolve problemas novos.

* **Underfitting (subajuste):** modelo demasiado simples; nÃ£o captura a estrutura dos dados. Performance ruim em treino e teste.

  *Analogia:* aluno que nÃ£o estudou o conteÃºdo.

### Como C4.5 ajuda?

* **Poda pÃ³s-crescimento (pessimistic pruning):** cresce Ã¡rvore atÃ© pureza e depois poda nÃ³s que nÃ£o reduzem o erro esperado â€” troca complexidade por generalizaÃ§Ã£o.

* **Melhor tratamento de atributos contÃ­nuos:** ponto de corte Ãºnico e estatisticamente justificado.

* **CritÃ©rios de parada / mÃ­nimos:** evita divisÃµes em nÃ³s com poucos exemplos (reduz regras espÃºrias).

### DemonstraÃ§Ã£o PrÃ¡tica com kNN

Para alÃ©m da discussÃ£o teÃ³rica, foi implementada uma anÃ¡lise prÃ¡tica na aplicaÃ§Ã£o web (`app.py`) para visualizar os fenÃ´menos de overfitting e underfitting. Na seÃ§Ã£o expansÃ­vel **"ğŸ”¬ AnÃ¡lise de Overfitting/Underfitting com kNN"**, Ã© possÃ­vel executar o algoritmo kNN no dataset de doenÃ§as cardÃ­acas com uma faixa de valores para o hiperparÃ¢metro *k*.

A aplicaÃ§Ã£o gera um grÃ¡fico interativo que plota a acurÃ¡cia do modelo em funÃ§Ã£o de *k*. Este grÃ¡fico demonstra empiricamente que:

*   **Valores de *k* muito baixos** (e.g., k=1) tendem a ter uma acurÃ¡cia volÃ¡til e podem se ajustar demais aos ruÃ­dos dos dados de treino (**overfitting**).
*   **Valores de *k* muito altos** suavizam demais a fronteira de decisÃ£o, fazendo o modelo perder a capacidade de capturar a complexidade dos dados e resultando em queda de performance (**underfitting**).
*   O valor Ã³timo de *k*, que maximiza a acurÃ¡cia no conjunto de teste, representa o melhor equilÃ­brio (bias-variance tradeoff) para este dataset.

---

## QuestÃ£o 6 â€” k-Nearest Neighbors (kNN)

### (a) Exemplo numÃ©rico (k = 1, 3, 7)

**Dataset (x (renda em x1000), y (idade)):**

```
P1 (50,30) â€” A
P2 (80,40) â€” B
P3 (90,35) â€” B
P4 (40,25) â€” A
P5 (85,45) â€” B
P6 (60,35) â€” A
P? (70,30) â€” ? (a classificar)
```

**DistÃ¢ncias euclidianas (cÃ¡lculo passo a passo):**

* d(P?,P1) = sqrt((70âˆ’50)Â² + (30âˆ’30)Â²) = sqrt(400+0) = 20.00
* d(P?,P2) = sqrt((70âˆ’80)Â² + (30âˆ’40)Â²) = sqrt(100+100) â‰ˆ 14.142 â†’ 14.14
* d(P?,P3) = sqrt((70âˆ’90)Â² + (30âˆ’35)Â²) = sqrt(400+25) â‰ˆ 20.616 â†’ 20.61
* d(P?,P4) = sqrt((70âˆ’40)Â² + (30âˆ’25)Â²) = sqrt(900+25) â‰ˆ 30.414 â†’ 30.41
* d(P?,P5) = sqrt((70âˆ’85)Â² + (30âˆ’45)Â²) = sqrt(225+225) â‰ˆ 21.213 â†’ 21.21
* d(P?,P6) = sqrt((70âˆ’60)Â² + (30âˆ’35)Â²) = sqrt(100+25) â‰ˆ 11.180 â†’ 11.18

**OrdenaÃ§Ã£o (mais prÃ³ximo â†’ mais distante):** P6, P2, P1, P3, P5, P4

* `k=1` â†’ vizinho: P6 (A) â†’ **A**
* `k=3` â†’ vizinhos: P6 (A), P2 (B), P1 (A) â†’ votaÃ§Ã£o (A:2, B:1) â†’ **A**
* `k=7` (aqui n=6 â†’ k=6): empate A:3 vs B:3 â†’ estratÃ©gias: desempate por soma/ mÃ©dia de distÃ¢ncias ou reduzir k (ex.: k Ã­mpar)

### (b) Como escolher k

* *Regra-de-polegar:* k â‰ˆ âˆšN (N = nÂº amostras).
* *Melhor prÃ¡tica:* validaÃ§Ã£o cruzada para testar vÃ¡rios k e escolher o que maximiza a mÃ©trica de interesse.

### (c) Falhas da distÃ¢ncia Euclidiana e alternativa (Gower)

* **Problema:** atributos com escalas diferentes e dados mistos (numÃ©rico + categÃ³rico).
* **Alternativa recomendada para dados mistos:** *DistÃ¢ncia de Gower* â€” normaliza numÃ©ricos (por range) e usa 0/1 para categÃ³ricos; soma ponderada dÃ¡ a distÃ¢ncia final.

Exemplo Gower (Renda em R\$):

* `|50000 âˆ’ 51000| / range = 1000 / 100000 = 0.01`
* Estado civil diferente â†’ distÃ¢ncia categÃ³rica = 1
* Gower mÃ©dia = (0.01 + 1) / 2 = 0.505

### (d) CenÃ¡rios onde kNN Ã© ineficaz

* Alta dimensionalidade (a vizinhanÃ§a perde sentido).
* Conjuntos de treino muito grandes (previsÃµes custosas).
* Classes fortemente desbalanceadas.
* Dados mistos sem uso de distÃ¢ncias apropriadas.

### (e) Lazy vs Eager

* **kNN:** *lazy* â€” quase nenhum treino, custo na prediÃ§Ã£o.
* **Ãrvores/SVM:** *eager* â€” treino caro, prediÃ§Ã£o rÃ¡pida.

### ImplementaÃ§Ã£o e AnÃ¡lise PrÃ¡tica

A implementaÃ§Ã£o prÃ¡tica deste algoritmo foi realizada em `knn_classifier.py` e integrada Ã  aplicaÃ§Ã£o principal de duas formas distintas:

1.  Um **exemplo didÃ¡tico** na seÃ§Ã£o "Explorador k-Nearest Neighbors", que permite classificar um Ãºnico ponto novo em um dataset 2D, visualizando os vizinhos mais prÃ³ximos.
2.  Uma **anÃ¡lise de sensibilidade do hiperparÃ¢metro *k***, conforme descrito na seÃ§Ã£o anterior (QuestÃµes 4 & 5), que utiliza o dataset de doenÃ§as cardÃ­acas para uma exploraÃ§Ã£o mais robusta do comportamento do algoritmo e para demonstrar visualmente os conceitos de overfitting e underfitting.

---

## Reprodutibilidade, limitaÃ§Ãµes e notas metodolÃ³gicas

* **CÃ¡lculos manuais:** realizados em papel; os scans/fotos estÃ£o em `sodeusnacausa/`. 
* **PrÃ©-processamento:** LabelEncoding foi usado para simplicidade didÃ¡tica. Em aplicaÃ§Ãµes reais, possivelmente utilizarÃ­amos `OneHotEncoding` e normalizaÃ§Ã£o, que Ã© importante.